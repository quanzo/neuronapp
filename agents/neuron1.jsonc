{
  // Пример конфигурации агента neuron1 в формате JSONC.
  // Структура повторяет PHP-конфигурацию из файла agents/neuron1.php.

  // Включить сохранение истории диалога в БД.
  "enableChatHistory": true,

  // Максимальный размер контекста LLM в токенах/символах.
  "contextWindow": 50000,

  // Опциональный идентификатор истории чата (null — использовать последнюю историю).
  "history_id": null,

  // Класс структурированного ответа (DTO), если требуется строгий формат вывода.
  "reponseStructClass": null,

  // Провайдер LLM через Ollama.
  //
  // Важно: структура массива соответствует расширенному callable-массиву
  // для CallableWrapper::call():
  // [CallableWrapper::class, "createObject", "class" => ..., "url" => ..., "parameters" => ..., "model" => ...]
  "provider": {
    "0": "app\\\\modules\\\\neuron\\\\helpers\\\\CallableWrapper",
    "1": "createObject",
    "class": "NeuronAI\\\\Providers\\\\Ollama\\\\Ollama",
    "url": "http://localhost:11434/api",
    "parameters": {
      "options": {
        // Температура — влияет на креативность ответа.
        "temperature": 0.1,
        // Nucleus Sampling (top_p) — ограничивает множество кандидатов.
        "top_p": 0.9,
        // Штраф за повторения — подавляет повторяющиеся фразы.
        "repeat_penalty": 1.1
      }
    },
    "model": "slekrem/gpt-oss-claude-code-32k:20b"
  },

  // Системный промпт (инструкции для агента) на основе NeuronAI\\SystemPrompt.
  "instructions": {
    "0": "app\\\\modules\\\\neuron\\\\helpers\\\\CallableWrapper",
    "1": "createObject",
    "class": "NeuronAI\\\\SystemPrompt",
    "background": [
      "Твое имя Джозеф",
      "Ты специалист по аналитике данных. Выводы ты должен делать на основании четких и проверенных сведений. Если данных не хватает, или есть подозрения, что данные не корректные, то: составь список запросов на поиск данных; затем выполни поиск по списку запросов применяя предоставленные инструменты и источники; собери полученные результаты и из них выбери релевантные; на основании релевантных данных строй выводы и гипотезы.",
      "Никогда не спрашивай об необходимости поиска - сразу ищи всю доступную информацию, во всех доступных источника!",
      "Приоритетный язык общения: русский. Используй другой язык только по прямому указанию пользователя!",
      "Используй все доступные источники и инструменты для выполнения заданий и получения данных",
      "При получении информации от внешних источников или инструментов тебе следует выбрать только те данные, которые относятся к заданию или вопросу пользователя!",
      "После формирования ответа требуется выполнить дополнительную проверку на релевантность вопросу или просьбе пользователя. Если подготовленные данные не корректны, то следует их актуализировать!",
      "Тебе запрещено выдумывать несуществующие данные!",
      "Твоя задача использовать только надежную и проверенную информацию! Обращайся к инструментам для получения информации!"
    ],
    "steps": [
      "Получи от пользователя задание на поиск и анализ информации.",
      "Сформируй аналитику на основаниий найденных данных"
    ],
    "output": [
      "Выведи итоги"
    ]
  },

  // Дополнительные инструменты, доступные агенту.
  "tools": [
    ["NeuronAI\\\\Tools\\\\Toolkits\\\\Calculator\\\\CalculatorToolkit", "make"],
    ["NeuronAI\\\\Tools\\\\Toolkits\\\\Calendar\\\\CurrentDateTimeTool", "make"],
    ["NeuronAI\\\\Tools\\\\Toolkits\\\\Calculator\\\\FactorialTool", "make"]
  ],

  // Пример конфигурации MCP (по умолчанию закомментирован).
  /*
  "mcp": [
    {
      "0": "NeuronAI\\\\MCP\\\\McpConnector",
      "1": "make",
      "config": {
        "command": "docker run -i --rm ddg_mcp_server",
        "type": "stdio"
      }
    }
  ],
  */

  // Векторное хранилище на базе Qdrant.
  "vectorStore": {
    "0": "app\\\\modules\\\\neuron\\\\helpers\\\\CallableWrapper",
    "1": "createObject",
    "2": "NeuronAI\\\\RAG\\\\VectorStore\\\\QdrantVectorStore",
    "collectionUrl": "http://localhost:6333/collections/neuron2/",
    "key": null,
    "topK": 4,
    "dimension": 768
  },

  // Конфигурация embedding-модели для генерации векторов.
  "embeddingProvider": {
    "0": "app\\\\modules\\\\neuron\\\\helpers\\\\CallableWrapper",
    "1": "createObject",
    "2": "NeuronAI\\\\RAG\\\\Embeddings\\\\OllamaEmbeddingsProvider",
    "model": "embeddinggemma:latest",
    "url": "http://localhost:11434/api"
  },

  // Размер текстового чанка (в символах) для построения эмбеддингов.
  "embeddingChunkSize": 1500,

  // Максимальное количество последовательных вызовов инструментов.
  "toolMaxTries": 5
}

